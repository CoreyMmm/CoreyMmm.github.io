---
layout: post
title: 'TEMPONet sEmg Recognization阅读整理（一）'
date: 2020-08-20
author: Tianmeng Wu
color: rgb(131,175,155)
cover: '../assets/TEMPONet/图片13.png'
tags: EMG GAP8 RISCV TCN


---

> Robust Real-Time Embedded EMG Recognition Framework Using Temporal Convolutional Networks on a Multicore IoT Processor
>
> author:Marcello Zanghieri, Simone Benatti , Alessio Burrello , Victor Kartsch , Francesco Conti , and Luca Benini

# 一、Introduction

​      手势编码是开发高级人机交互的重要方法，有着广阔的应用场景。通常可以通过计算机视觉方法或肌电信号分析两种方法进行实现。CV方法通过对图像的处理对大量的手势进行编码，但其依赖于预先布置的相机，同时容易受到光照环境和视线的影响。而通过机器学习的方法对肌电信号进行分析，同样可以取得较好的效果，但其不利之处在于——信号源容易受到测试者测试过程中的疲劳、适应度或者电极位移等因素的影响。这些因素严重影响了基于肌电信号的设备的稳定性。因此，可以考虑使用深度学习的方法对肌电信号分析进行改进。深度学习不需要人工提取的特征，在模型的训练过程中，可以学习到人不易察觉的特征表达，从而可以取得更好的泛化效果。

   但深度学习模型往往需要大量的参数，这意味着在算法运行时需要比较大的内存，而搭载肌电信号处理的设备往往都是只有几MB的内存。所以在实际部署解决一个问题时需要：（1）训练一个优秀的网络模型；（2）减少网络的参数量；（3）结合具体嵌入式设备进行优化。

​     在这篇文章中，作者提出了一个基于时序卷积网络的手势识别系统，且这个系统可以实时地运行在嵌入式系统中。作者的工作在多个测试数据集中，均达到了最先进水平。总的来说，文章的贡献如下：

1.  TEMPONet,一个基于EMG信号的手势识别模型；

2. 一个完整的可以采集和处理肌电信号的嵌入式系统。这个系统包括一个商用的生物信号采集前端和一个多核低功耗物联网处理器GAP8；

3. 一个包含20段信号的数据集。

# BACKGROUND AND RELATED WORK

###   	1.EMG信号与数据集：

​        EMG信号是离子流通过肌纤维膜产生的电流产生的生物电位，因此，它是肌肉活动的主要指标。这种电位是由来自中枢神经系统的电刺激产生的，并通过支配肌肉组织的运动神经元产生的。通常，肌电信号的振幅范围为10μV至10 mV，带宽为∼2kHz。此外，它是一个非常具有挑战性的信号，因为它易受到多种噪声源干扰，如运动伪影、浮动地面噪声、串扰和电力线等。

 EMG数据可以通过有创或无创的方法获得。在这项工作中，我们将重点放在表面肌电图（sEMG），这是一种使用电极在皮肤表面操作的无创技术。在表面肌电设置中，可以使用仪器放大器检测动作电位（AP），正负端子连接到皮肤表面上的两个金属板上；sEMG信号是由放大器下方所有检测到的AP叠加而成的。在人机界面（HMI）领域，基于表面肌电信号的手势识别是最有前途的方法之一，因为非侵入性是许多人机交互的基本要求。

 非侵入性自适应手部假肢数据库6（NinaPro DB6）是一个公共sEMG数据库，用于研究基于sEMG的手势识别的可重复性。数据收集自10名完整（即非截肢）受试者（3名女性，7名男性，平均年龄27±6岁）。数据库由10个部分组成（5天，一天两次：上午和下午），每一次包括对7种抓握姿势的12次重复，每一次10个人都参与。抓具选自机器人学和康复文献，涵盖日常生活活动的典型手部运动。用14个表面肌电无线电极，置于前臂上半部，采样率为2khz，测量表面肌电信号。每次抓握重复大约持续6秒，然后休息2秒。

   除了对Nina Pro DB6进行的分析外，我们还介绍了对我们的数据集的研究，它包含了我们嵌入式平台中真实场景的影响。这个数据集以完全兼容人机交互的手势为目标。为了分析表面肌电时间变异性并验证我们的结果，我们使用我们定制的8电极平台收集了一个20个会话的数据集。

### 	2.时序卷积网络

​    时序卷积网络模型在很多基于时间序列的处理中，展现了良好的性能。其具有两大特性：

1. 因果性。即时刻t的输出只来源于时刻t之前的所有的数据输入

2. 膨胀性。在TCN中，引入了膨胀系数，其实质是数据之间的时序间隔，这保证了数据接收域足够大。

文中采用的一个网络组件如下：

![]({{ "/assets/TEMPONet/图片1.png" | absolute_url }})



### 3.相关研究

   在过去的几年中发表的基于sEMG信号的手势识别研究都使用相同的系统结构，即（1）一个用于生物信号采集的模拟前端、（2）一个数据预处理和特征提取/选择的中间部件和（3）用一个分类的处理后端。通常采用的算法是SVM、RF、ANN等机器学习算法。

![]({{ "/assets/TEMPONet/图片2.png" | absolute_url }})

   有许多研究者进行了相关研究，但其问题在于他们都**只在单段数据中进行了研究，因而无法解决在不同数据间试验的问题**。当这些算法运行在一段模型从未见过的数据时，通常会有明显的准确率下降。因而，研究者的视野逐渐从追求绝对的算法准确率转移到追求在不同数据或者不稳定的数据集上的泛化效果上来。本文的工作正是由此展开。







# MATERIALS AND METHODS

### 	1. 信号获取与处理平台

  EMG信号采集由连接到GAP8开发套件的8通道模拟前端ADS1298完成。ADS1298主要用于EMG，EEG和ECG信号的采集系统，已成为此类应用的事实标准，它允许以24位分辨率同时采样多达8个双极通道，采样率达32ksps。每个通道都有一个可编程增益放大器，增益范围从1到12。在本文应用中，它以4 kHz的采样率驱动8个完全差分通道，这些通道连接到一系列EMG电极。GAP8具有两个主要功能块：控制器（FC）和8个并行的RISCV计算核心集群。FC控制Soc和外设，可以看作是一个简单的微控制器。8核集群用于向量化和并行化的计算密集型任务，如嵌入式人工智能。

  GAP8没有FPU，所以算法都需要被转化成定点运算。GAP8拥有L1和L2两级缓存。L1缓存512KB，可被所有核心访问。L1缓存又被分为两部分，一部分16KB大小，仅可被FC访问的，另一部分64KB，可被所有其他集群核心访问。实际上也可以有L3，但必须通过HyperBus或者SPI额外链接。此外GAP8还有电源系统。

  所有的代码用C完成，并运行在GAP8处理器上。开发基于GAP8 SDK完成，GAP8 SDK有一个定制的RISCV GCC 编译器，并支持可用于深度神经网络加速的拓展指令集。如图所示，一个ADS1298通过一个20MHz SPI并行连接到GAP8的数据引脚上。当一个新的样本数据准备好之后，ADS1298就将一个data ready的中断信号传给FC，FC则会调用对应的中断处理程序，通过DMA方式读取数据。通过SPI传输的数据将会以24位有符号定点数的形式存储在L2中，其最低有效位代表基准电压。这些数据最终将作为TEMPONet的输入。

### 	2.TEMPONet TCN

![]({{ "/assets/TEMPONet/图片3.png" | absolute_url }})

​      此文中采用的网络结构如上图，一共有三个卷积层，滤波器的大小分别为3*1、3*1和5*1，dilation d =2, 4, 8, respectively, and stride s =1, 2, 4，接着是一个AVG池化层，然后连接两层全连接的神经网络，FC中都有dropout层和softmax操作，最终，将原始的150ms长的是EMG信号分类到标签。其中，所有的神经元均使用了ReLU作为激活函数，并进行批标准化。在最终的网络中，该模型处理一段150ms的数据只需要460K个参数。接下来，作者对模型进行了**量化压缩**，将模型中的浮点数据和浮点运算转化成了定点数据和定点运算。

  在gap8处理器中，在L2使用双buffer来实时接受从ADS1298传输过来的数据。模型的其他实现，利用**PULP-NN**这个库完成，这个库充分地利用了RISCV芯片的计算性能，来提高了量化神经网络的推理速度。当PULP-NN的函数在L1缓存上运行时，需要将权重数据和特征数据从L1搬回到L2。这个步骤利用了一个**自动工具**实现，有两个作用，一是将每层中的数据张量划分为适合L1大小的块，二是插入适当的DMA调用以实现双缓冲方案（与ADC数据上的缓冲方案分开），这样就可以使得数据I/O与计算一直处于重叠状态。值得一提的时，DMA是异步和非阻塞的，这才使得当前一次的计算还在进行时，可以从L2读取下一次计算所需要的权重和激活函数。计算流程如下图所示。

 ![]({{ "/assets/TEMPONet/图片4.png" | absolute_url }})

​     

**量化压缩方法**：J. Choi et al., “PACT: Parameterized clipping activation for quantized neural networks,” May 2018, arXiv:1805.06085 [cs]

**PULP-NN库**：“PULP-NN: Accelerating quantized neural networks on parallel ultra-low-power RISC-V processors,” Aug. 2019, arXiv:1908.11263 [cs]

**数据自动传输工具**：“Work-in-progress: DORY: Lightweight memory hierarchymanagement for deep NN inference on IoT endnodes,” in Proc. Int. Conf. Hardw./Soft. Codes. Syst. Synthesis, to be published.



